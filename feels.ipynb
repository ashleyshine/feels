{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Sentence\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Processing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = './scripts'\n",
    "script_name = 'Thanksgiving.txt'\n",
    "with open(\"{}/{}\".format(script_dir, script_name), 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\\n  [Bob Barker] The first\\n Showcase Showdown.\\n  On its way, ladies and gentlemen.\\n  It is round and around and around\\n that it goes.\\n  [cheers and applause on TV]\\n  Where Denise at?\\n  She upstairs with her little boyfriend.\\n  [laughing] Oh, wait.\\n Denise got a little boyfriend?\\n  - Mm-hmm.\\n - [laughs]\\n  [cheers and applause on TV]\\n  Y'all better stop running\\n through this house.\\n  [Denise] Yes, Grandma.\\n  Denise, what were y'all doing up there?\\n  Watching Fresh Prince.\\n  You weren't eating candy, were you?\\n  No.\\n  Dev, do y'all even celebrate\\n Thanksgiving in your house?\\n  Is that a thing y'all do\\n in the Indian community?\\n  We have lunch together.\\n  Then my dad watches The Godfather\\n and falls asleep.\\n  [laughs]\\n  Well, you are welcome to come have\\n  Thanksgiving with us anytime you want.\\n  What's the Indian community?\\n  [laughs]\\n  Dev is Indian.\\n  Wait. I thought Dev was black.\\n  - I'm brown.\\n - Black people are brown, too.\\n  [Catherine] Oh, Lord.\\n  Okay.\\n  Look, both of you are min\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got some things that aren't part of the dialogue here: names like [Denise] and [Catherine], and actions like [laughs] and [cheers and applause on TV]. While the latter can give some context to the mood of the scene, I'm making an executive decision here to remove them since I want to limit my analysis to the script dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Return text with special characters and non-dialogue (e.g. [laughs], [Denise]) removed.\n",
    "    Params:\n",
    "        text: string\n",
    "    \"\"\"\n",
    "    text = re.sub(r'^1\\s*', '', text) # scraped scripts start with 1\n",
    "    dialogue = re.sub(r'\\[.*\\]', '', text)\n",
    "    return re.sub('[^A-Za-z0-9\\'?!. ]+', '', dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I analyze word usage frequency, I want to exclude common stopwords without an particular significance like \"the\" and \"and\". Just gonna leave this here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    Return text with stopwords removed.\n",
    "    Note that this removes punctuation like (!?.,) as well.\n",
    "    Params:\n",
    "        text: string\n",
    "    \"\"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    blob = TextBlob(text)\n",
    "    words = [word for word in blob.words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text_no_stopwords = remove_stop_words(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at what we've got now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The first Showcase Showdown.  On its way ladies and gentlemen.  It is round and around and around that it goes.    Where Denise at?  She upstairs with her little boyfriend.   Oh wait. Denise got a little boyfriend?   Mmhmm.      Y'all better stop running through this house.   Yes Grandma.  Denise what were y'all doing up there?  Watching Fresh Prince.  You weren't eating candy were you?  No.  Dev do y'all even celebrate Thanksgiving in your house?  Is that a thing y'all do in the Indian community?  We have lunch together.  Then my dad watches The Godfather and falls asleep.    Well you are welcome to come have  Thanksgiving with us anytime you want.  What's the Indian community?    Dev is Indian.  Wait. I thought Dev was black.   I'm brown.  Black people are brown too.   Oh Lord.  Okay.  Look both of you are minorities.  What's a minority?  It's a group of people who have to work  twice as hard in life to get half as far  and Denise you a black woman  so you gonna have to work three t\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall sentiment of entire episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.12602021893037516, subjectivity=0.5488213854382333)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_polarities(blob):\n",
    "    \"\"\"\n",
    "    Return dictionary with {sentence (string): polarity} for sentences in blob.\n",
    "    Params:\n",
    "        blob: TextBlob\n",
    "    \"\"\"\n",
    "    sentence_polarities = {}\n",
    "\n",
    "    for sent in blob.sentences:\n",
    "        polarity = sent.sentiment.polarity\n",
    "        sentence_polarities[str(sent)] = polarity\n",
    "        \n",
    "    return sentence_polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_polarities = get_sentence_polarities(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now I have a dictionary mapping sentences to their respective polarities. I'm gonna load all of that into a dataframe now and see what we can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df = pd.DataFrame(list(sentence_polarities.items()), columns=['sentence', 'polarity'])\n",
    "sorted_sentences = sentence_df.sort_values(by=['polarity'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Positive Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence|Polarity\n",
      "I'm happy for you.|0.8\n",
      "They're great.|0.8\n",
      "Welcome darling.|0.8\n",
      "Well you are welcome to come have  Thanksgiving with us anytime you want.|0.8\n",
      "I said your yams turned out really nice this year!|0.75\n",
      "Grandma Ernestine your yams turned out really nice this year!|0.75\n",
      "That's good to know.|0.7\n",
      "Yeah man it's really good.|0.7\n",
      "It's so great to  Nice to meet you.|0.7\n",
      "They good?|0.7\n"
     ]
    }
   ],
   "source": [
    "print('Sentence|Polarity')\n",
    "for index, row, in sorted_sentences[:10].iterrows():\n",
    "    print('{}|{}'.format(row['sentence'], row['polarity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Negative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence|Polarity\n",
      "Horrible.|-1.0\n",
      "That's horrible.|-1.0\n",
      "Damn why you got to hate on the Pan?|-0.8\n",
      "That character was an idiot.|-0.8\n",
      "Stupid.|-0.7999999999999999\n",
      "seventeenfoot aluminum boat that broke apart    Man I told you this is stupid.|-0.7999999999999999\n",
      "Don't you ask another fucking question!|-0.75\n",
      "Well you know my hearing is bad.|-0.6999999999999998\n",
      "Why would they be mad?|-0.625\n",
      "I feel like all three of them are gonna be mad at you about that.|-0.625\n"
     ]
    }
   ],
   "source": [
    "print('Sentence|Polarity')\n",
    "for index, row, in sorted_sentences[::-1][:10].iterrows():\n",
    "    print('{}|{}'.format(row['sentence'], row['polarity']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feels",
   "language": "python",
   "name": "feels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
